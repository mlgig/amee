{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "matplotlib.rcParams['font.family'] = 'sans-serif'\n",
    "matplotlib.rcParams['font.sans-serif'] = 'Arial'\n",
    "\n",
    "import operator\n",
    "import math\n",
    "from scipy.stats import wilcoxon\n",
    "from scipy.stats import friedmanchisquare\n",
    "import networkx\n",
    "import utils.process_result as process_result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/hfawaz/cd-diagram\n",
    "# inspired from orange3 https://docs.orange.biolab.si/3/data-mining-library/reference/evaluation.cd.html\n",
    "def graph_ranks(avranks, names, p_values, cd=None, cdmethod=None, lowv=None, highv=None,\n",
    "                width=6, textspace=1, reverse=False, filename=None, labels=False, **kwargs):\n",
    "    \"\"\"\n",
    "    Draws a CD graph, which is used to display  the differences in methods'\n",
    "    performance. See Janez Demsar, Statistical Comparisons of Classifiers over\n",
    "    Multiple Data Sets, 7(Jan):1--30, 2006.\n",
    "    Needs matplotlib to work.\n",
    "    The image is ploted on `plt` imported using\n",
    "    `import matplotlib.pyplot as plt`.\n",
    "    Args:\n",
    "        avranks (list of float): average ranks of methods.\n",
    "        names (list of str): names of methods.\n",
    "        cd (float): Critical difference used for statistically significance of\n",
    "            difference between methods.\n",
    "        cdmethod (int, optional): the method that is compared with other methods\n",
    "            If omitted, show pairwise comparison of methods\n",
    "        lowv (int, optional): the lowest shown rank\n",
    "        highv (int, optional): the highest shown rank\n",
    "        width (int, optional): default width in inches (default: 6)\n",
    "        textspace (int, optional): space on figure sides (in inches) for the\n",
    "            method names (default: 1)\n",
    "        reverse (bool, optional):  if set to `True`, the lowest rank is on the\n",
    "            right (default: `False`)\n",
    "        filename (str, optional): output file name (with extension). If not\n",
    "            given, the function does not write a file.\n",
    "        labels (bool, optional): if set to `True`, the calculated avg rank\n",
    "        values will be displayed\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import matplotlib\n",
    "        import matplotlib.pyplot as plt\n",
    "        from matplotlib.backends.backend_agg import FigureCanvasAgg\n",
    "    except ImportError:\n",
    "        raise ImportError(\"Function graph_ranks requires matplotlib.\")\n",
    "\n",
    "    width = float(width)\n",
    "    textspace = float(textspace)\n",
    "\n",
    "    def nth(l, n):\n",
    "        \"\"\"\n",
    "        Returns only nth elemnt in a list.\n",
    "        \"\"\"\n",
    "        n = lloc(l, n)\n",
    "        return [a[n] for a in l]\n",
    "\n",
    "    def lloc(l, n):\n",
    "        \"\"\"\n",
    "        List location in list of list structure.\n",
    "        Enable the use of negative locations:\n",
    "        -1 is the last element, -2 second last...\n",
    "        \"\"\"\n",
    "        if n < 0:\n",
    "            return len(l[0]) + n\n",
    "        else:\n",
    "            return n\n",
    "\n",
    "    def mxrange(lr):\n",
    "        \"\"\"\n",
    "        Multiple xranges. Can be used to traverse matrices.\n",
    "        This function is very slow due to unknown number of\n",
    "        parameters.\n",
    "        >>> mxrange([3,5])\n",
    "        [(0, 0), (0, 1), (0, 2), (1, 0), (1, 1), (1, 2)]\n",
    "        >>> mxrange([[3,5,1],[9,0,-3]])\n",
    "        [(3, 9), (3, 6), (3, 3), (4, 9), (4, 6), (4, 3)]\n",
    "        \"\"\"\n",
    "        if not len(lr):\n",
    "            yield ()\n",
    "        else:\n",
    "            # it can work with single numbers\n",
    "            index = lr[0]\n",
    "            if isinstance(index, int):\n",
    "                index = [index]\n",
    "            for a in range(*index):\n",
    "                for b in mxrange(lr[1:]):\n",
    "                    yield tuple([a] + list(b))\n",
    "\n",
    "    def print_figure(fig, *args, **kwargs):\n",
    "        canvas = FigureCanvasAgg(fig)\n",
    "        canvas.print_figure(*args, **kwargs)\n",
    "\n",
    "    sums = avranks\n",
    "\n",
    "    nnames = names\n",
    "    ssums = sums\n",
    "\n",
    "    if lowv is None:\n",
    "        lowv = min(1, int(math.floor(min(ssums))))\n",
    "    if highv is None:\n",
    "        highv = max(len(avranks), int(math.ceil(max(ssums))))\n",
    "\n",
    "    cline = 0.4\n",
    "\n",
    "    k = len(sums)\n",
    "\n",
    "    lines = None\n",
    "\n",
    "    linesblank = 0\n",
    "    scalewidth = width - 2 * textspace\n",
    "\n",
    "    def rankpos(rank):\n",
    "        if not reverse:\n",
    "            a = rank - lowv\n",
    "        else:\n",
    "            a = highv - rank\n",
    "        return textspace + scalewidth / (highv - lowv) * a\n",
    "\n",
    "    distanceh = 0.25\n",
    "\n",
    "    cline += distanceh\n",
    "\n",
    "    # calculate height needed height of an image\n",
    "    minnotsignificant = max(2 * 0.2, linesblank)\n",
    "    height = cline + ((k + 1) / 2) * 0.2 + minnotsignificant\n",
    "\n",
    "    fig = plt.figure(figsize=(width, height))\n",
    "    fig.set_facecolor('white')\n",
    "    ax = fig.add_axes([0, 0, 1, 1])  # reverse y axis\n",
    "    ax.set_axis_off()\n",
    "\n",
    "    hf = 1. / height  # height factor\n",
    "    wf = 1. / width\n",
    "\n",
    "    def hfl(l):\n",
    "        return [a * hf for a in l]\n",
    "\n",
    "    def wfl(l):\n",
    "        return [a * wf for a in l]\n",
    "\n",
    "    # Upper left corner is (0,0).\n",
    "    ax.plot([0, 1], [0, 1], c=\"w\")\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(1, 0)\n",
    "\n",
    "    def line(l, color='k', **kwargs):\n",
    "        \"\"\"\n",
    "        Input is a list of pairs of points.\n",
    "        \"\"\"\n",
    "        ax.plot(wfl(nth(l, 0)), hfl(nth(l, 1)), color=color, **kwargs)\n",
    "\n",
    "    def text(x, y, s, *args, **kwargs):\n",
    "        ax.text(wf * x, hf * y, s, *args, **kwargs)\n",
    "\n",
    "    line([(textspace, cline), (width - textspace, cline)], linewidth=2)\n",
    "\n",
    "    bigtick = 0.3\n",
    "    smalltick = 0.15\n",
    "    linewidth = 2.0\n",
    "    linewidth_sign = 4.0\n",
    "\n",
    "    tick = None\n",
    "    for a in list(np.arange(lowv, highv, 0.5)) + [highv]:\n",
    "        tick = smalltick\n",
    "        if a == int(a):\n",
    "            tick = bigtick\n",
    "        line([(rankpos(a), cline - tick / 2),\n",
    "              (rankpos(a), cline)],\n",
    "             linewidth=2)\n",
    "\n",
    "    for a in range(lowv, highv + 1):\n",
    "        text(rankpos(a), cline - tick / 2 - 0.05, str(a),\n",
    "             ha=\"center\", va=\"bottom\", size=16)\n",
    "\n",
    "    k = len(ssums)\n",
    "\n",
    "    def filter_names(name):\n",
    "        return name\n",
    "\n",
    "    space_between_names = 0.24\n",
    "\n",
    "    for i in range(math.ceil(k / 2)):\n",
    "        chei = cline + minnotsignificant + i * space_between_names\n",
    "        line([(rankpos(ssums[i]), cline),\n",
    "              (rankpos(ssums[i]), chei),\n",
    "              (textspace - 0.1, chei)],\n",
    "             linewidth=linewidth)\n",
    "        if labels:\n",
    "            text(textspace + 0.3, chei - 0.075, format(ssums[i], '.4f'), ha=\"right\", va=\"center\", size=10)\n",
    "        text(textspace - 0.2, chei, filter_names(nnames[i]), ha=\"right\", va=\"center\", size=16)\n",
    "\n",
    "    for i in range(math.ceil(k / 2), k):\n",
    "        chei = cline + minnotsignificant + (k - i - 1) * space_between_names\n",
    "        line([(rankpos(ssums[i]), cline),\n",
    "              (rankpos(ssums[i]), chei),\n",
    "              (textspace + scalewidth + 0.1, chei)],\n",
    "             linewidth=linewidth)\n",
    "        if labels:\n",
    "            text(textspace + scalewidth - 0.3, chei - 0.075, format(ssums[i], '.4f'), ha=\"left\", va=\"center\", size=10)\n",
    "        text(textspace + scalewidth + 0.2, chei, filter_names(nnames[i]),\n",
    "             ha=\"left\", va=\"center\", size=16)\n",
    "\n",
    "    # no-significance lines\n",
    "    def draw_lines(lines, side=0.05, height=0.1):\n",
    "        start = cline + 0.2\n",
    "\n",
    "        for l, r in lines:\n",
    "            line([(rankpos(ssums[l]) - side, start),\n",
    "                  (rankpos(ssums[r]) + side, start)],\n",
    "                 linewidth=linewidth_sign)\n",
    "            start += height\n",
    "            print('drawing: ', l, r)\n",
    "\n",
    "    # draw_lines(lines)\n",
    "    start = cline + 0.2\n",
    "    side = -0.02\n",
    "    height = 0.1\n",
    "\n",
    "    # draw no significant lines\n",
    "    # get the cliques\n",
    "    cliques = form_cliques(p_values, nnames)\n",
    "    i = 1\n",
    "    achieved_half = False\n",
    "    print(nnames)\n",
    "    for clq in cliques:\n",
    "        if len(clq) == 1:\n",
    "            continue\n",
    "        print(clq)\n",
    "        min_idx = np.array(clq).min()\n",
    "        max_idx = np.array(clq).max()\n",
    "        if min_idx >= len(nnames) / 2 and achieved_half == False:\n",
    "            start = cline + 0.25\n",
    "            achieved_half = True\n",
    "        line([(rankpos(ssums[min_idx]) - side, start),\n",
    "              (rankpos(ssums[max_idx]) + side, start)],\n",
    "             linewidth=linewidth_sign)\n",
    "        start += height\n",
    "\n",
    "\n",
    "def form_cliques(p_values, nnames):\n",
    "    \"\"\"\n",
    "    This method forms the cliques\n",
    "    \"\"\"\n",
    "    # first form the numpy matrix data\n",
    "    m = len(nnames)\n",
    "    g_data = np.zeros((m, m), dtype=np.int64)\n",
    "    for p in p_values:\n",
    "        if p[3] == False:\n",
    "            i = np.where(nnames == p[0])[0][0]\n",
    "            j = np.where(nnames == p[1])[0][0]\n",
    "            min_i = min(i, j)\n",
    "            max_j = max(i, j)\n",
    "            g_data[min_i, max_j] = 1\n",
    "\n",
    "    g = networkx.Graph(g_data)\n",
    "    return networkx.find_cliques(g)\n",
    "\n",
    "\n",
    "def draw_cd_diagram(df_perf=None, alpha=0.05, title=None, labels=False):\n",
    "    \"\"\"\n",
    "    Draws the critical difference diagram given the list of pairwise classifiers that are\n",
    "    significant or not\n",
    "    \"\"\"\n",
    "    p_values, average_ranks, _ = wilcoxon_holm(df_perf=df_perf, alpha=alpha)\n",
    "\n",
    "    print(average_ranks)\n",
    "\n",
    "    for p in p_values:\n",
    "        print(p)\n",
    "\n",
    "\n",
    "    graph_ranks(average_ranks.values, average_ranks.keys(), p_values,\n",
    "                cd=None, reverse=True, width=9, textspace=1.5, labels=labels)\n",
    "\n",
    "    font = {'family': 'sans-serif',\n",
    "        'color':  'black',\n",
    "        'weight': 'normal',\n",
    "        'size': 22,\n",
    "        }\n",
    "    if title:\n",
    "        plt.title(title,fontdict=font, y=0.9, x=0.5)\n",
    "    plt.savefig('img/cd-diagram.png',bbox_inches='tight', dpi=300)\n",
    "\n",
    "def wilcoxon_holm(alpha=0.05, df_perf=None, ):\n",
    "    \"\"\"\n",
    "    Applies the wilcoxon signed rank test between each pair of algorithm and then use Holm\n",
    "    to reject the null's hypothesis\n",
    "    \"\"\"\n",
    "    print(pd.unique(df_perf['XAI_method']))\n",
    "    # count the number of tested datasets per classifier\n",
    "    df_counts = pd.DataFrame({'count': df_perf.groupby(\n",
    "        ['XAI_method']).size()}).reset_index()\n",
    "    # get the maximum number of tested datasets\n",
    "    max_nb_datasets = df_counts['count'].max()\n",
    "    # get the list of classifiers who have been tested on nb_max_datasets\n",
    "    classifiers = list(df_counts.loc[df_counts['count'] == max_nb_datasets]\n",
    "                       ['XAI_method'])\n",
    "    # test the null hypothesis using friedman before doing a post-hoc analysis\n",
    "    friedman_p_value = friedmanchisquare(*(\n",
    "        np.array(df_perf.loc[df_perf['XAI_method'] == c]['explanation_power'])\n",
    "        for c in classifiers))[1]\n",
    "    if friedman_p_value >= alpha:\n",
    "        # then the null hypothesis over the entire classifiers cannot be rejected\n",
    "        print('the null hypothesis over the entire classifiers cannot be rejected')\n",
    "        exit()\n",
    "    # get the number of classifiers\n",
    "    m = len(classifiers)\n",
    "    # init array that contains the p-values calculated by the Wilcoxon signed rank test\n",
    "    p_values = []\n",
    "    # loop through the algorithms to compare pairwise\n",
    "    for i in range(m - 1):\n",
    "        # get the name of classifier one\n",
    "        classifier_1 = classifiers[i]\n",
    "        # get the performance of classifier one\n",
    "        perf_1 = np.array(df_perf.loc[df_perf['XAI_method'] == classifier_1]['explanation_power']\n",
    "                          , dtype=np.float64)\n",
    "        for j in range(i + 1, m):\n",
    "            # get the name of the second classifier\n",
    "            classifier_2 = classifiers[j]\n",
    "            # get the performance of classifier one\n",
    "            perf_2 = np.array(df_perf.loc[df_perf['XAI_method'] == classifier_2]\n",
    "                              ['explanation_power'], dtype=np.float64)\n",
    "            # calculate the p_value\n",
    "            p_value = wilcoxon(perf_1, perf_2, zero_method='pratt')[1]\n",
    "            # appen to the list\n",
    "            p_values.append((classifier_1, classifier_2, p_value, False))\n",
    "    # get the number of hypothesis\n",
    "    k = len(p_values)\n",
    "    # sort the list in acsending manner of p-value\n",
    "    p_values.sort(key=operator.itemgetter(2))\n",
    "\n",
    "    # loop through the hypothesis\n",
    "    for i in range(k):\n",
    "        # correct alpha with holm\n",
    "        new_alpha = float(alpha / (k - i))\n",
    "        # test if significant after holm's correction of alpha\n",
    "        if p_values[i][2] <= new_alpha:\n",
    "            p_values[i] = (p_values[i][0], p_values[i][1], p_values[i][2], True)\n",
    "        else:\n",
    "            # stop\n",
    "            break\n",
    "    # compute the average ranks to be returned (useful for drawing the cd diagram)\n",
    "    # sort the dataframe of performances\n",
    "    sorted_df_perf = df_perf.loc[df_perf['XAI_method'].isin(classifiers)]. \\\n",
    "        sort_values(['XAI_method', 'dataset'])\n",
    "    # get the rank data\n",
    "    rank_data = np.array(sorted_df_perf['explanation_power']).reshape(m, max_nb_datasets)\n",
    "\n",
    "    # create the data frame containg the accuracies\n",
    "    df_ranks = pd.DataFrame(data=rank_data, index=np.sort(classifiers), columns=\n",
    "    np.unique(sorted_df_perf['dataset']))\n",
    "\n",
    "    # number of wins\n",
    "    dfff = df_ranks.rank(ascending=False)\n",
    "    print(dfff[dfff == 1.0].sum(axis=1))\n",
    "\n",
    "    # average the ranks\n",
    "    average_ranks = df_ranks.rank(ascending=False).mean(axis=1).sort_values(ascending=False)\n",
    "    # return the p-values and the average ranks\n",
    "    return p_values, average_ranks, max_nb_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trang\\Google Drive\\github\\explanation4tsc-2nd\\utils\\process_result.py:299: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['average_scaled_auc'] = (df['metrics: explanation_auc']-min_)/(max_-min_)\n",
      "C:\\Users\\trang\\Google Drive\\github\\explanation4tsc-2nd\\utils\\process_result.py:299: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['average_scaled_auc'] = (df['metrics: explanation_auc']-min_)/(max_-min_)\n",
      "C:\\Users\\trang\\Google Drive\\github\\explanation4tsc-2nd\\utils\\process_result.py:299: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['average_scaled_auc'] = (df['metrics: explanation_auc']-min_)/(max_-min_)\n",
      "C:\\Users\\trang\\Google Drive\\github\\explanation4tsc-2nd\\utils\\process_result.py:301: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['average_scaled_auc'] = (df['metrics: explanation_auc']-min_)/1.0\n",
      "C:\\Users\\trang\\Google Drive\\github\\explanation4tsc-2nd\\utils\\process_result.py:299: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['average_scaled_auc'] = (df['metrics: explanation_auc']-min_)/(max_-min_)\n",
      "C:\\Users\\trang\\Google Drive\\github\\explanation4tsc-2nd\\utils\\process_result.py:299: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['average_scaled_auc'] = (df['metrics: explanation_auc']-min_)/(max_-min_)\n",
      "C:\\Users\\trang\\Google Drive\\github\\explanation4tsc-2nd\\utils\\process_result.py:299: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['average_scaled_auc'] = (df['metrics: explanation_auc']-min_)/(max_-min_)\n",
      "C:\\Users\\trang\\Google Drive\\github\\explanation4tsc-2nd\\utils\\process_result.py:299: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['average_scaled_auc'] = (df['metrics: explanation_auc']-min_)/(max_-min_)\n",
      "C:\\Users\\trang\\Google Drive\\github\\explanation4tsc-2nd\\utils\\process_result.py:301: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['average_scaled_auc'] = (df['metrics: explanation_auc']-min_)/1.0\n",
      "C:\\Users\\trang\\Google Drive\\github\\explanation4tsc-2nd\\utils\\process_result.py:299: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['average_scaled_auc'] = (df['metrics: explanation_auc']-min_)/(max_-min_)\n",
      "C:\\Users\\trang\\Google Drive\\github\\explanation4tsc-2nd\\utils\\process_result.py:299: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['average_scaled_auc'] = (df['metrics: explanation_auc']-min_)/(max_-min_)\n",
      "C:\\Users\\trang\\Google Drive\\github\\explanation4tsc-2nd\\utils\\process_result.py:299: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['average_scaled_auc'] = (df['metrics: explanation_auc']-min_)/(max_-min_)\n",
      "C:\\Users\\trang\\Google Drive\\github\\explanation4tsc-2nd\\utils\\process_result.py:299: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['average_scaled_auc'] = (df['metrics: explanation_auc']-min_)/(max_-min_)\n",
      "C:\\Users\\trang\\Google Drive\\github\\explanation4tsc-2nd\\utils\\process_result.py:299: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['average_scaled_auc'] = (df['metrics: explanation_auc']-min_)/(max_-min_)\n",
      "C:\\Users\\trang\\Google Drive\\github\\explanation4tsc-2nd\\utils\\process_result.py:299: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['average_scaled_auc'] = (df['metrics: explanation_auc']-min_)/(max_-min_)\n",
      "C:\\Users\\trang\\Google Drive\\github\\explanation4tsc-2nd\\utils\\process_result.py:299: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['average_scaled_auc'] = (df['metrics: explanation_auc']-min_)/(max_-min_)\n",
      "C:\\Users\\trang\\Google Drive\\github\\explanation4tsc-2nd\\utils\\process_result.py:299: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['average_scaled_auc'] = (df['metrics: explanation_auc']-min_)/(max_-min_)\n",
      "C:\\Users\\trang\\Google Drive\\github\\explanation4tsc-2nd\\utils\\process_result.py:299: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['average_scaled_auc'] = (df['metrics: explanation_auc']-min_)/(max_-min_)\n",
      "C:\\Users\\trang\\Google Drive\\github\\explanation4tsc-2nd\\utils\\process_result.py:299: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['average_scaled_auc'] = (df['metrics: explanation_auc']-min_)/(max_-min_)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>XAI_method</th>\n",
       "      <th>average_scaled_auc</th>\n",
       "      <th>scaled_ranking</th>\n",
       "      <th>explanation_power</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Car</td>\n",
       "      <td>GradientSHAP</td>\n",
       "      <td>0.696946</td>\n",
       "      <td>0.854589</td>\n",
       "      <td>0.145411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Car</td>\n",
       "      <td>Int Gradient</td>\n",
       "      <td>0.772522</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Car</td>\n",
       "      <td>MrSEQL-LIME</td>\n",
       "      <td>0.556206</td>\n",
       "      <td>0.583799</td>\n",
       "      <td>0.416201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Car</td>\n",
       "      <td>ROCKET-LIME</td>\n",
       "      <td>0.583798</td>\n",
       "      <td>0.636887</td>\n",
       "      <td>0.363113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Car</td>\n",
       "      <td>MrSEQL-SM</td>\n",
       "      <td>0.602676</td>\n",
       "      <td>0.673210</td>\n",
       "      <td>0.326790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CMJ</td>\n",
       "      <td>MrSEQL-SM</td>\n",
       "      <td>0.163210</td>\n",
       "      <td>0.098475</td>\n",
       "      <td>0.901525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CMJ</td>\n",
       "      <td>MrSEQL-SHAP</td>\n",
       "      <td>0.090130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CMJ</td>\n",
       "      <td>Random</td>\n",
       "      <td>0.656147</td>\n",
       "      <td>0.762709</td>\n",
       "      <td>0.237291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CMJ</td>\n",
       "      <td>RidgeCV-SM</td>\n",
       "      <td>0.605428</td>\n",
       "      <td>0.694364</td>\n",
       "      <td>0.305636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CMJ</td>\n",
       "      <td>ROCKET-SHAP</td>\n",
       "      <td>0.209695</td>\n",
       "      <td>0.161113</td>\n",
       "      <td>0.838887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset    XAI_method  average_scaled_auc  scaled_ranking  \\\n",
       "0      Car  GradientSHAP            0.696946        0.854589   \n",
       "1      Car  Int Gradient            0.772522        1.000000   \n",
       "2      Car   MrSEQL-LIME            0.556206        0.583799   \n",
       "3      Car   ROCKET-LIME            0.583798        0.636887   \n",
       "4      Car     MrSEQL-SM            0.602676        0.673210   \n",
       "..     ...           ...                 ...             ...   \n",
       "4      CMJ     MrSEQL-SM            0.163210        0.098475   \n",
       "5      CMJ   MrSEQL-SHAP            0.090130        0.000000   \n",
       "6      CMJ        Random            0.656147        0.762709   \n",
       "7      CMJ    RidgeCV-SM            0.605428        0.694364   \n",
       "8      CMJ   ROCKET-SHAP            0.209695        0.161113   \n",
       "\n",
       "    explanation_power  \n",
       "0            0.145411  \n",
       "1            0.000000  \n",
       "2            0.416201  \n",
       "3            0.363113  \n",
       "4            0.326790  \n",
       "..                ...  \n",
       "4            0.901525  \n",
       "5            1.000000  \n",
       "6            0.237291  \n",
       "7            0.305636  \n",
       "8            0.838887  \n",
       "\n",
       "[153 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GET long table for Critical diagram \n",
    "\n",
    "df = process_result.summarize_result(synthetic_data=False,wide_table=False)\n",
    "\n",
    "conditions = [\n",
    "    df['XAI_method']=='GS',\n",
    "    df['XAI_method']=='IG',\n",
    "    df['XAI_method']=='lime_mrseql',\n",
    "    df['XAI_method']=='lime_rocket',\n",
    "    df['XAI_method']=='rocket-shap',\n",
    "    df['XAI_method']=='mrseql-shap',\n",
    "    df['XAI_method']=='random2020',\n",
    "    df['XAI_method']=='ridgecv',\n",
    "    df['XAI_method']=='mrseql',]\n",
    "\n",
    "values = ['GradientSHAP', 'Int Gradient', 'MrSEQL-LIME', 'ROCKET-LIME', 'ROCKET-SHAP', 'MrSEQL-SHAP', 'Random',\n",
    "         'RidgeCV-SM', 'MrSEQL-SM']\n",
    "\n",
    "df['XAI_method'] = np.select(conditions, values)\n",
    "\n",
    "# df.to_csv('img/result_ucr_longtable.csv',index=False,  float_format='%.5f')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GradientSHAP' 'Int Gradient' 'MrSEQL-LIME' 'ROCKET-LIME' 'MrSEQL-SM'\n",
      " 'MrSEQL-SHAP' 'Random' 'RidgeCV-SM' 'ROCKET-SHAP']\n",
      "GradientSHAP    2.0\n",
      "Int Gradient    2.0\n",
      "MrSEQL-LIME     0.0\n",
      "MrSEQL-SHAP     5.0\n",
      "MrSEQL-SM       0.0\n",
      "ROCKET-LIME     0.0\n",
      "ROCKET-SHAP     8.0\n",
      "Random          0.0\n",
      "RidgeCV-SM      0.0\n",
      "dtype: float64\n",
      "Random          6.470588\n",
      "RidgeCV-SM      6.411765\n",
      "MrSEQL-SM       6.411765\n",
      "ROCKET-LIME     5.176471\n",
      "MrSEQL-LIME     4.882353\n",
      "Int Gradient    4.882353\n",
      "GradientSHAP    4.823529\n",
      "MrSEQL-SHAP     3.529412\n",
      "ROCKET-SHAP     2.411765\n",
      "dtype: float64\n",
      "('MrSEQL-SHAP', 'MrSEQL-SM', 0.0004207907816778689, True)\n",
      "('ROCKET-SHAP', 'RidgeCV-SM', 0.0004207907816778689, True)\n",
      "('ROCKET-SHAP', 'Random', 0.0004989830887916685, True)\n",
      "('ROCKET-LIME', 'ROCKET-SHAP', 0.0011841930356640954, True)\n",
      "('MrSEQL-SM', 'ROCKET-SHAP', 0.0016341069790478376, False)\n",
      "('MrSEQL-SHAP', 'Random', 0.001644006329825974, False)\n",
      "('MrSEQL-LIME', 'MrSEQL-SM', 0.003090081924360667, False)\n",
      "('MrSEQL-LIME', 'MrSEQL-SHAP', 0.0035993565836257646, False)\n",
      "('MrSEQL-LIME', 'ROCKET-SHAP', 0.0064899700076656245, False)\n",
      "('MrSEQL-SHAP', 'RidgeCV-SM', 0.009871788182927657, False)\n",
      "('MrSEQL-SHAP', 'ROCKET-LIME', 0.011322371449485434, False)\n",
      "('GradientSHAP', 'ROCKET-SHAP', 0.02168170376271011, False)\n",
      "('GradientSHAP', 'RidgeCV-SM', 0.02454049897109125, False)\n",
      "('Int Gradient', 'ROCKET-SHAP', 0.02454049897109125, False)\n",
      "('Int Gradient', 'RidgeCV-SM', 0.03124928092967935, False)\n",
      "('MrSEQL-LIME', 'Random', 0.044233691013677856, False)\n",
      "('GradientSHAP', 'Random', 0.05521337554271477, False)\n",
      "('Int Gradient', 'Random', 0.05521337554271477, False)\n",
      "('MrSEQL-LIME', 'RidgeCV-SM', 0.07586833499439012, False)\n",
      "('ROCKET-LIME', 'Random', 0.13592202165385756, False)\n",
      "('MrSEQL-LIME', 'ROCKET-LIME', 0.1625717591562893, False)\n",
      "('Int Gradient', 'MrSEQL-SM', 0.17729327255318428, False)\n",
      "('MrSEQL-SM', 'ROCKET-LIME', 0.19298546891685997, False)\n",
      "('GradientSHAP', 'MrSEQL-SM', 0.22738526970373263, False)\n",
      "('MrSEQL-SHAP', 'ROCKET-SHAP', 0.22738526970373263, False)\n",
      "('GradientSHAP', 'MrSEQL-SHAP', 0.24613691576742636, False)\n",
      "('GradientSHAP', 'Int Gradient', 0.2659466461059248, False)\n",
      "('Int Gradient', 'MrSEQL-SHAP', 0.286759822294811, False)\n",
      "('ROCKET-LIME', 'RidgeCV-SM', 0.40743445607773554, False)\n",
      "('Int Gradient', 'ROCKET-LIME', 0.43475617175843206, False)\n",
      "('GradientSHAP', 'ROCKET-LIME', 0.5227810104666994, False)\n",
      "('Random', 'RidgeCV-SM', 0.5227810104666994, False)\n",
      "('MrSEQL-SM', 'Random', 0.7945864126678862, False)\n",
      "('GradientSHAP', 'MrSEQL-LIME', 0.831310207979425, False)\n",
      "('Int Gradient', 'MrSEQL-LIME', 0.8684061308988609, False)\n",
      "('MrSEQL-SM', 'RidgeCV-SM', 0.9057940914405992, False)\n",
      "Index(['Random', 'RidgeCV-SM', 'MrSEQL-SM', 'ROCKET-LIME', 'MrSEQL-LIME',\n",
      "       'Int Gradient', 'GradientSHAP', 'MrSEQL-SHAP', 'ROCKET-SHAP'],\n",
      "      dtype='object')\n",
      "[4, 5, 6, 0, 1, 3, 2]\n",
      "[4, 5, 6, 0, 1, 3, 7]\n",
      "[4, 5, 6, 8, 2]\n",
      "[4, 5, 6, 8, 7]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>XAI_method</th>\n",
       "      <th>average_scaled_auc</th>\n",
       "      <th>scaled_ranking</th>\n",
       "      <th>explanation_power</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Car</td>\n",
       "      <td>GradientSHAP</td>\n",
       "      <td>0.696946</td>\n",
       "      <td>0.854589</td>\n",
       "      <td>0.145411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Car</td>\n",
       "      <td>Int Gradient</td>\n",
       "      <td>0.772522</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Car</td>\n",
       "      <td>MrSEQL-LIME</td>\n",
       "      <td>0.556206</td>\n",
       "      <td>0.583799</td>\n",
       "      <td>0.416201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Car</td>\n",
       "      <td>ROCKET-LIME</td>\n",
       "      <td>0.583798</td>\n",
       "      <td>0.636887</td>\n",
       "      <td>0.363113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Car</td>\n",
       "      <td>MrSEQL-SM</td>\n",
       "      <td>0.602676</td>\n",
       "      <td>0.673210</td>\n",
       "      <td>0.326790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CMJ</td>\n",
       "      <td>MrSEQL-SM</td>\n",
       "      <td>0.163210</td>\n",
       "      <td>0.098475</td>\n",
       "      <td>0.901525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CMJ</td>\n",
       "      <td>MrSEQL-SHAP</td>\n",
       "      <td>0.090130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CMJ</td>\n",
       "      <td>Random</td>\n",
       "      <td>0.656147</td>\n",
       "      <td>0.762709</td>\n",
       "      <td>0.237291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CMJ</td>\n",
       "      <td>RidgeCV-SM</td>\n",
       "      <td>0.605428</td>\n",
       "      <td>0.694364</td>\n",
       "      <td>0.305636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CMJ</td>\n",
       "      <td>ROCKET-SHAP</td>\n",
       "      <td>0.209695</td>\n",
       "      <td>0.161113</td>\n",
       "      <td>0.838887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset    XAI_method  average_scaled_auc  scaled_ranking  \\\n",
       "0      Car  GradientSHAP            0.696946        0.854589   \n",
       "1      Car  Int Gradient            0.772522        1.000000   \n",
       "2      Car   MrSEQL-LIME            0.556206        0.583799   \n",
       "3      Car   ROCKET-LIME            0.583798        0.636887   \n",
       "4      Car     MrSEQL-SM            0.602676        0.673210   \n",
       "..     ...           ...                 ...             ...   \n",
       "4      CMJ     MrSEQL-SM            0.163210        0.098475   \n",
       "5      CMJ   MrSEQL-SHAP            0.090130        0.000000   \n",
       "6      CMJ        Random            0.656147        0.762709   \n",
       "7      CMJ    RidgeCV-SM            0.605428        0.694364   \n",
       "8      CMJ   ROCKET-SHAP            0.209695        0.161113   \n",
       "\n",
       "    explanation_power  \n",
       "0            0.145411  \n",
       "1            0.000000  \n",
       "2            0.416201  \n",
       "3            0.363113  \n",
       "4            0.326790  \n",
       "..                ...  \n",
       "4            0.901525  \n",
       "5            1.000000  \n",
       "6            0.237291  \n",
       "7            0.305636  \n",
       "8            0.838887  \n",
       "\n",
       "[153 rows x 5 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# df = pd.read_csv('img/result_ucr_longtable.csv', index_col=False)\n",
    "# df = pd.wide_to_long(df_perf)\n",
    "draw_cd_diagram(df_perf=df, title='Explanation Power', labels=False)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>random2020</th>\n",
       "      <th>GS</th>\n",
       "      <th>IG</th>\n",
       "      <th>lime_mrseql</th>\n",
       "      <th>lime_rocket</th>\n",
       "      <th>mrseql-shap</th>\n",
       "      <th>rocket-shap</th>\n",
       "      <th>mrseql</th>\n",
       "      <th>ridgecv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CBF</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TwoPatterns</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ECG200</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ECG5000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ECGFiveDays</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TwoLeadECG</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GunPoint</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CMJ</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PowerCons</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Coffee</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Strawberry</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Car</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ItalyPower</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Plane</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Sony1</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Sony2</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Trace</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        dataset  random2020    GS    IG  lime_mrseql  lime_rocket  \\\n",
       "0           CBF        0.00  0.77  0.72         0.70         0.90   \n",
       "1   TwoPatterns        0.00  0.86  0.85         0.89         0.95   \n",
       "2        ECG200        0.00  0.13  0.17         0.67         0.57   \n",
       "3       ECG5000        0.00  1.00  0.99         0.67         0.57   \n",
       "4   ECGFiveDays        0.54  0.77  0.71         0.39         0.54   \n",
       "5    TwoLeadECG        0.39  0.17  0.18         0.44         0.40   \n",
       "6      GunPoint        0.81  0.74  1.00         0.77         0.00   \n",
       "7           CMJ        0.24  0.06  0.00         0.99         0.56   \n",
       "8     PowerCons        0.50  0.69  0.68         0.37         0.76   \n",
       "9        Coffee        0.00  0.36  0.53         0.53         0.37   \n",
       "10   Strawberry        0.65  0.41  0.43         0.91         0.66   \n",
       "11          Car        0.45  0.15  0.00         0.42         0.36   \n",
       "12   ItalyPower        0.27  1.00  0.95         0.16         0.13   \n",
       "13        Plane        0.75  0.80  0.78         0.50         0.00   \n",
       "14        Sony1        0.23  0.84  0.80         0.21         0.52   \n",
       "15        Sony2        0.32  0.99  1.00         0.45         0.41   \n",
       "16        Trace        0.33  0.25  0.21         0.77         0.26   \n",
       "\n",
       "    mrseql-shap  rocket-shap  mrseql  ridgecv  \n",
       "0          1.00         0.84    0.77     0.27  \n",
       "1          0.83         1.00    0.88     0.52  \n",
       "2          0.84         1.00    0.46     0.45  \n",
       "3          0.61         0.82    0.30     0.29  \n",
       "4          0.91         1.00    0.00     0.27  \n",
       "5          0.92         1.00    0.05     0.00  \n",
       "6          0.92         0.84    0.89     0.56  \n",
       "7          1.00         0.84    0.90     0.31  \n",
       "8          0.45         1.00    0.00     0.66  \n",
       "9          0.86         1.00    0.72     0.57  \n",
       "10         1.00         0.40    0.70     0.00  \n",
       "11         1.00         0.74    0.33     0.44  \n",
       "12         0.11         0.29    0.00     0.54  \n",
       "13         0.67         1.00    0.19     0.32  \n",
       "14         0.32         1.00    0.00     0.83  \n",
       "15         0.37         0.82    0.00     0.57  \n",
       "16         1.00         0.79    0.16     0.00  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
